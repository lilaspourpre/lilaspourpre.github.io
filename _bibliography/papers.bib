---
---

@inproceedings{moskvoretskii-etal-2024-taxollama,
    title = {TaxoLLaMA: WordNet-based Model for Solving Multiple Lexical Semantic Tasks.},
    author = {Moskvoretskii, Viktor and
      Neminova, Ekaterina  and
      Lobanova, Alina  and
      Panchenko, Alexander and 
      Nikishina, Irina}
    booktitle = {Proceedings of the 62nd Conference of the Association for Computational Linguistics},
    month = {aug}
    year = {2024},
    address = {Bangkok, Tailand},
    publisher = {Association for Computational Linguistics},
    url = {https://aclanthology.org/},
    dimensions = {false},
    bibtex_show= {true},
    selected = {true}
}

@article{moskvoretskii2024low,
  title={Low-Resource Machine Translation through the Lens of Personalized Federated Learning},
  author={Moskvoretskii, Viktor and Tupitsa, Nazarii and Biemann, Chris and Horv{\'a}th, Samuel and Gorbunov, Eduard and Nikishina, Irina},
  journal={arXiv preprint arXiv:2406.12564},
  year={2024},
  dimensions = {false},
  bibtex_show= {true},
  selected = {true},
  abstract = {We present a new approach based on the Personalized Federated Learning algorithm MeritFed that can be applied to Natural Language Tasks with heterogeneous data. We evaluate it on the Low-Resource Machine Translation task, using the dataset from the Large-Scale Multilingual Machine Translation Shared Task (Small Track #2) and the subset of Sami languages from the multilingual benchmark for Finno-Ugric languages. In addition to its effectiveness, MeritFed is also highly interpretable, as it can be applied to track the impact of each language used for training. Our analysis reveals that target dataset size affects weight distribution across auxiliary languages, that unrelated languages do not interfere with the training, and auxiliary optimizer parameters have minimal impact. Our approach is easy to apply with a few lines of code, and we provide scripts for reproducing the experiments at thishttps://github.com/VityaVitalich/MeritFed}
}

@inproceedings{nikishina-et-al-2024-industry,
title = {Industry vs Academia: Running a Course on Transformers in Two Setups},
author = {Nikishina, Irina and
          Tikhonova, Maria and
          Chekalina, Viktoria and
          Zaytsev, Alexey and
          Vazhentsev, Artem and
          Panchenko, Alexander},
booktitle = {Proceedings of the Sixth Workshop on Teaching NLP},
month = {aug},
year = {2024},
address = {Bangkok, Thailand},
publisher = {Association for Computational Linguistics},
bibtex_show={true},
  }

@inproceedings{guenzler-et-al-2024-sovereign,
title = {Soevereign at PerpectiveArg2024: Using LLMs with Argument Mining},
author = {Guenzler, Robert and Sevgili, Oezge and Remus, Steffen and Biemann, Chris and Nikishina, Irina},
booktitle = {Proceedings of the 11th Workshop on Argument Mining},
    month = {aug},
    year = {2024},
    address = {Bangkok, Thailand},
    publisher = {Association for Computational Linguistics},
bibtex_show={true},
  }

@inproceedings{strich-et-al-2024-improving,
title = {On Improving Repository-Level Code QA for Large Language Models},
author = {Strich, Jan, and Schneider, Florian and Nikishina, Irina and Biemann, Chris},
booktitle = {Proceedings of the ACL Student Research Workshop},
    month = {aug},
    year = {2024},
    address = {Bangkok, Thailand},
    publisher = {Association for Computational Linguistics},
bibtex_show={true},
  }

@inproceedings{sakhovskiy-et-al-2024-textgraphs,
title = {TextGraphs 2024 Shared Task on Text-Graph Representations for Knowledge Graph Question Answering},
author = {Sakhovskiy, Andrey and Salnikov, Mikhail and Nikishina, Irina and Usmanova, Aida and Kraft, Angelie and MÃ¶ller, Cedric and Banerjee, Debayan and Huang, Junbo and Jiang, Longquan and Abdullah, Rana and Yan, Xi and Tutubalina, Elena and Usbeck, Ricardo and Panchenko, Alexander},
booktitle = {Proceedings of the Seventeen Workshop on Graph-Based Methods for Natural Language Processing (TextGraphs-17)},
    month = {aug},
    year = {2024},
    address = {Bangkok, Thailand},
    publisher = {Association for Computational Linguistics},
bibtex_show={true},
  }

@article{nikishinaextending,
  title={Extending the Comparative Argumentative Machine: Multilingualism and Stance Detection},
  author={Nikishina, Irina and Bondarenko, Alexander and Zaczek, Sebastian and Haag, Onno Lander and Hagen, Matthias and Biemann, Chris},
  booktitle={RATIO},
  year={2024},
  bibtex_show={true},
}

@article{rouhizadeh2023biowic,
  title={BioWiC: An Evaluation Benchmark for Biomedical Concept Representation},
  author={Rouhizadeh, Hossein and Nikishina, Irina and Yazdani, Anthony and Bornet, Alban and Zhang, Boya and Ehrsam, Julien and Gaudet-Blavignac, Christophe and Naderi, Nona and Teodoro, Douglas},
  journal={Scientific Data 11},
  pages={2024--11 (455)},
  year={2024},
  publisher={Nature},
  bibtex_show={true},
  url={https://www.biorxiv.org/content/10.1101/2023.11.08.566170v1}
}

@inproceedings{moskvoretskii-etal-2024-large-language,
    title = "Are Large Language Models Good at Lexical Semantics? A Case of Taxonomy Learning",
    author = "Moskvoretskii, Viktor  and
      Panchenko, Alexander  and
      Nikishina, Irina",
    editor = "Calzolari, Nicoletta  and
      Kan, Min-Yen  and
      Hoste, Veronique  and
      Lenci, Alessandro  and
      Sakti, Sakriani  and
      Xue, Nianwen",
    booktitle = "Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",
    month = may,
    year = "2024",
    address = "Torino, Italia",
    publisher = "ELRA and ICCL",
    url = "https://aclanthology.org/2024.lrec-main.133",
    pages = "1498--1510",
    dimensions = false,
    bibtex_show=true,
    abstract = "Recent studies on LLMs do not pay enough attention to linguistic and lexical semantic tasks, such as taxonomy learning. In this paper, we explore the capacities of Large Language Models featuring LLaMA-2 and Mistral for several Taxonomy-related tasks. We introduce a new methodology and algorithm for data collection via stochastic graph traversal leading to controllable data collection. Collected cases provide the ability to form nearly any type of graph operation. We test the collected dataset for learning taxonomy structure based on English WordNet and compare different input templates for fine-tuning LLMs. Moreover, we apply the fine-tuned models on such datasets on the downstream tasks achieving state-of-the-art results on the TexEval-2 dataset.",
}

@inproceedings{shallouf-etal-2024-cam-2,
    title = "{CAM} 2.0: End-to-End Open Domain Comparative Question Answering System",
    author = "Shallouf, Ahmad  and
      Herasimchyk, Hanna  and
      Salnikov, Mikhail  and
      Garrido Veliz, Rudy Alexandro  and
      Mestvirishvili, Natia  and
      Panchenko, Alexander  and
      Biemann, Chris  and
      Nikishina, Irina",
    editor = "Calzolari, Nicoletta  and
      Kan, Min-Yen  and
      Hoste, Veronique  and
      Lenci, Alessandro  and
      Sakti, Sakriani  and
      Xue, Nianwen",
    booktitle = "Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",
    month = may,
    year = "2024",
    address = "Torino, Italia",
    publisher = "ELRA and ICCL",
    url = "https://aclanthology.org/2024.lrec-main.238",
    pages = "2657--2672",
    dimensions = false,
    bibtex_show=true,
    abstract = "Comparative Question Answering (CompQA) is a Natural Language Processing task that combines Question Answering and Argument Mining approaches to answer subjective comparative questions in an efficient argumentative manner. In this paper, we present an end-to-end (full pipeline) system for answering comparative questions called CAM 2.0 as well as a public leaderboard called CompUGE that unifies the existing datasets under a single easy-to-use evaluation suite. As compared to previous web-form-based CompQA systems, it features question identification, object and aspect labeling, stance classification, and summarization using up-to-date models. We also select the most time- and memory-effective pipeline by comparing separately fine-tuned Transformer Encoder models which show state-of-the-art performance on the subtasks with Generative LLMs in few-shot and LoRA setups. We also conduct a user study for a whole-system evaluation.",
}

@inproceedings{DBLP:conf/aist/MaslovaRAZBN23,
  author       = {Maria Maslova and
                  Stefan Rebrikov and
                  Anton Artsishevski and
                  Sebastian Zaczek and
                  Chris Biemann and
                  Irina Nikishina},
  title        = {RuCAM: Comparative Argumentative Machine for the Russian Language},
  booktitle    = {{AIST}},
  series       = {Lecture Notes in Computer Science},
  volume       = {14486},
  pages        = {78--91},
  publisher    = {Springer},
  year         = {2023},
  dimensions = {false},
  bibtex_show = {true}
}

@inproceedings{DBLP:conf/aist/ChernomorchenkoPN23,
  author       = {Polina Chernomorchenko and
                  Alexander Panchenko and
                  Irina Nikishina},
  title        = {Leveraging Taxonomic Information from Large Language Models for Hyponymy
                  Prediction},
  booktitle    = {{AIST}},
  series       = {Lecture Notes in Computer Science},
  volume       = {14486},
  pages        = {49--63},
  publisher    = {Springer},
  year         = {2023},
  bibtex_show = {true}
}

@inproceedings{salnikov-etal-2023-large,
    title = "Large Language Models Meet Knowledge Graphs to Answer Factoid Questions",
    author = "Salnikov, Mikhail  and
      Le, Hai  and
      Rajput, Prateek  and
      Nikishina, Irina  and
      Braslavski, Pavel  and
      Malykh, Valentin  and
      Panchenko, Alexander",
    editor = "Huang, Chu-Ren  and
      Harada, Yasunari  and
      Kim, Jong-Bok  and
      Chen, Si  and
      Hsu, Yu-Yin  and
      Chersoni, Emmanuele  and
      A, Pranav  and
      Zeng, Winnie Huiheng  and
      Peng, Bo  and
      Li, Yuxi  and
      Li, Junlin",
    booktitle = "Proceedings of the 37th Pacific Asia Conference on Language, Information and Computation",
    month = dec,
    year = "2023",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.paclic-1.63",
    pages = "635--644",
    bibtex_show=true,
    dimensions = false
}

@inproceedings{nikishina-etal-2023-predicting,
    title = "Predicting Terms in {IS}-A Relations with Pre-trained Transformers",
    author = "Nikishina, Irina  and
      Chernomorchenko, Polina  and
      Demidova, Anastasiia  and
      Panchenko, Alexander  and
      Biemann, Chris",
    editor = "Park, Jong C.  and
      Arase, Yuki  and
      Hu, Baotian  and
      Lu, Wei  and
      Wijaya, Derry  and
      Purwarianti, Ayu  and
      Krisnadhi, Adila Alfa",
    booktitle = "Findings of the Association for Computational Linguistics: IJCNLP-AACL 2023 (Findings)",
    month = nov,
    year = "2023",
    address = "Nusa Dua, Bali",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-ijcnlp.12",
    doi = "10.18653/v1/2023.findings-ijcnlp.12",
    pages = "134--148",
    dimensions = false,
    bibtex_show=true
}

@inproceedings{nikishina-etal-2022-cross,
    title = "Cross-Modal Contextualized Hidden State Projection Method for Expanding of Taxonomic Graphs",
    author = "Nikishina, Irina  and
      Vakhitova, Alsu  and
      Tutubalina, Elena  and
      Panchenko, Alexander",
    editor = "Ustalov, Dmitry  and
      Gao, Yanjun  and
      Panchenko, Alexander  and
      Valentino, Marco  and
      Thayaparan, Mokanarangan  and
      Nguyen, Thien Huu  and
      Penn, Gerald  and
      Ramesh, Arti  and
      Jana, Abhik",
    booktitle = "Proceedings of TextGraphs-16: Graph-based Methods for Natural Language Processing",
    month = oct,
    year = "2022",
    address = "Gyeongju, Republic of Korea",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.textgraphs-1.2",
    pages = "11--24",
    dimensions = false,
    bibtex_show=true,
    abstract = "Taxonomy is a graph of terms organized hierarchically using is-a (hypernymy) relations. We suggest novel candidate-free task formulation for the taxonomy enrichment task. To solve the task, we leverage lexical knowledge from the pre-trained models to predict new words missing in the taxonomic resource. We propose a method that combines graph-, and text-based contextualized representations from transformer networks to predict new entries to the taxonomy. We have evaluated the method suggested for this task against text-only baselines based on BERT and fastText representations. The results demonstrate that incorporation of graph embedding is beneficial in the task of hyponym prediction using contextualized models. We hope the new challenging task will foster further research in automatic text graph construction methods.",
}

@article{DBLP:journals/corr/abs-2206-09249,
  author       = {Evgeny V. Kotelnikov and
                  Natalia V. Loukachevitch and
                  Irina Nikishina and
                  Alexander Panchenko},
  title        = {RuArg-2022: Argument Mining Evaluation},
  booktitle    = {Computational Linguistics and Intellectual Technologies},
  year         = {2022},
  bibtex_show  = {true},
}

@article{russe2022detoxification,
  title={RUSSE-2022: Findings of the First Russian Detoxification Task Based on Parallel Corpora},
  author={Dementieva, Daryna and Nikishina, Irina and Logacheva, Varvara and Fenogenova, Alena and Dale, David and Krotova, Irina and Semenov, Nikita and Shavrina, Tatiana and Panchenko, Alexander},
  booktitle={Computational Linguistics and Intellectual Technologies},
  year={2022},
  bibtex_show  = {true}
}

@inproceedings{nikishina-etal-2022-taxfree,
    title = "{T}ax{F}ree: a Visualization Tool for Candidate-free Taxonomy Enrichment",
    author = "Nikishina, Irina  and
      Andrianov, Ivan  and
      Vakhitova, Alsu  and
      Panchenko, Alexander",
    editor = "Buntine, Wray  and
      Liakata, Maria",
    booktitle = "Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing: System Demonstrations",
    month = nov,
    year = "2022",
    address = "Taipei, Taiwan",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.aacl-demo.5",
    pages = "39--47",
    dimensions = false,
    bibtex_show=true,
    abstract = "Taxonomies are widely used in a various number of downstream NLP tasks and, therefore, should be kept up-to-date. In this paper, we present TaxFree, an open source system for taxonomy visualisation and automatic Taxonomy Enrichment without pre-defined candidates on the example of WordNet-3.0. As oppose to the traditional task formulation (where the list of new words is provided beforehand), we provide an approach for automatic extension of a taxonomy using a large pre-trained language model. As an advantage to the existing visualisation tools of WordNet, TaxFree also integrates graphic representations of synsets from ImageNet. Such visualisation tool can be used for both updating taxonomies and inspecting them for the required modifications.",
}

@inproceedings{logacheva-etal-2022-study,
    title = "A Study on Manual and Automatic Evaluation for Text Style Transfer: The Case of Detoxification",
    author = "Logacheva, Varvara  and
      Dementieva, Daryna  and
      Krotova, Irina  and
      Fenogenova, Alena  and
      Nikishina, Irina  and
      Shavrina, Tatiana  and
      Panchenko, Alexander",
    editor = "Belz, Anya  and
      Popovi{\'c}, Maja  and
      Reiter, Ehud  and
      Shimorina, Anastasia",
    booktitle = "Proceedings of the 2nd Workshop on Human Evaluation of NLP Systems (HumEval)",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.humeval-1.8",
    pages = "90--101",
    dimensions = false,
    bibtex_show=true,
    abstract = "It is often difficult to reliably evaluate models which generate text. Among them, text style transfer is a particularly difficult to evaluate, because its success depends on a number of parameters. We conduct an evaluation of a large number of models on a detoxification task. We explore the relations between the manual and automatic metrics and find that there is only weak correlation between them, which is dependent on the type of model which generated text. Automatic metrics tend to be less reliable for better-performing models. However, our findings suggest that, ChrF and BertScore metrics can be used as a proxy for human evaluation of text detoxification to some extent.",
}

@article{DBLP:journals/semweb/NikishinaTLNPL22,
  author       = {Irina Nikishina and
                  Mikhail Tikhomirov and
                  Varvara Logacheva and
                  Yuriy Nazarov and
                  Alexander Panchenko and
                  Natalia V. Loukachevitch},
  title        = {Taxonomy enrichment with text and graph vector representations},
  journal      = {Semantic Web},
  volume       = {13},
  number       = {3},
  pages        = {441--475},
  year         = {2022},
  bibtex_show = {true},
}

@inproceedings{nikishina-etal-2021-evaluation,
    title = "Evaluation of Taxonomy Enrichment on Diachronic {W}ord{N}et Versions",
    author = "Nikishina, Irina  and
      Loukachevitch, Natalia  and
      Logacheva, Varvara  and
      Panchenko, Alexander",
    editor = "Vossen, Piek  and
      Fellbaum, Christiane",
    booktitle = "Proceedings of the 11th Global Wordnet Conference",
    month = jan,
    year = "2021",
    address = "University of South Africa (UNISA)",
    publisher = "Global Wordnet Association",
    url = "https://aclanthology.org/2021.gwc-1.15",
    pages = "126--136",
    dimensions = false,
    bibtex_show=true,
    abstract = "The vast majority of the existing approaches for taxonomy enrichment apply word embeddings as they have proven to accumulate contexts (in a broad sense) extracted from texts which are sufficient for attaching orphan words to the taxonomy. On the other hand, apart from being large lexical and semantic resources, taxonomies are graph structures. Combining word embeddings with graph structure of taxonomy could be of use for predicting taxonomic relations. In this paper we compare several approaches for attaching new words to the existing taxonomy which are based on the graph representations with the one that relies on fastText embeddings. We test all methods on Russian and English datasets, but they could be also applied to other wordnets and languages.",
}

@inproceedings{DBLP:conf/aist/Nikishina21,
  author       = {Irina Nikishina},
  title        = {Taxonomy Enrichment with Text and Graph Vector Representation},
  booktitle    = {{AIST}},
  series       = {Lecture Notes in Computer Science},
  volume       = {13217},
  pages        = {9--19},
  publisher    = {Springer},
  year         = {2021},
  bibtex_show = {true},
}

@inproceedings{nikishina-etal-2020-studying,
    title = "Studying Taxonomy Enrichment on Diachronic {W}ord{N}et Versions",
    author = "Nikishina, Irina  and
      Logacheva, Varvara  and
      Panchenko, Alexander  and
      Loukachevitch, Natalia",
    editor = "Scott, Donia  and
      Bel, Nuria  and
      Zong, Chengqing",
    booktitle = "Proceedings of the 28th International Conference on Computational Linguistics",
    month = dec,
    year = "2020",
    address = "Barcelona, Spain (Online)",
    publisher = "International Committee on Computational Linguistics",
    url = "https://aclanthology.org/2020.coling-main.276",
    pages = "3095--3106",
    selected = true,
    bibtex_show=true,
    abstract = "Ontologies, taxonomies, and thesauri have always been in high demand in a large number of NLP tasks. However, most studies are focused on the creation of lexical resources rather than the maintenance of the existing ones and keeping them up-to-date. In this paper, we address the problem of taxonomy enrichment. Namely, we explore the possibilities of taxonomy extension in a resource-poor setting and present several methods which are applicable to a large number of languages. We also create novel English and Russian datasets for training and evaluating taxonomy enrichment systems and describe a technique of creating such datasets for other languages.",
}

@inproceedings{DBLP:conf/aist/SafaryanFYKN20,
  author       = {Anna Safaryan and
                  Petr Filchenkov and
                  Weijia Yan and
                  Andrey Kutuzov and
                  Irina Nikishina},
  title        = {Semantic Recommendation System for Bilingual Corpus of Academic Papers},
  booktitle    = {{AIST} (Supplement)},
  series       = {Communications in Computer and Information Science},
  volume       = {1357},
  pages        = {22--36},
  publisher    = {Springer},
  year         = {2021},
  bibtex_show= {true},
}

@article{DBLP:journals/corr/abs-2005-11176,
  author       = {Irina Nikishina and
                  Varvara Logacheva and
                  Alexander Panchenko and
                  Natalia V. Loukachevitch},
  title        = {RUSSE'2020: Findings of the First Taxonomy Enrichment Task for the
                  Russian language},
  journal      = {CoRR},
  volume       = {abs/2005.11176},
  year         = {2020},
  bibtex_show= {true},
}

@inproceedings{DBLP:conf/aist/SysoevN19,
  author       = {Andrey Sysoev and
                  Irina Nikishina},
  title        = {Deep JEDi: Deep Joint Entity Disambiguation to Wikipedia for Russian},
  booktitle    = {{AIST}},
  series       = {Lecture Notes in Computer Science},
  volume       = {11832},
  pages        = {230--241},
  publisher    = {Springer},
  year         = {2019},
  bibtex_show= {true},
}

@inproceedings{DBLP:conf/aist/KutuzovN19,
  author       = {Andrey Kutuzov and
                  Irina Nikishina},
  title        = {Double-Blind Peer-Reviewing and Inclusiveness in Russian {NLP} Conferences},
  booktitle    = {{AIST}},
  series       = {Lecture Notes in Computer Science},
  volume       = {11832},
  pages        = {3--8},
  publisher    = {Springer},
  year         = {2019},
  bibtex_show= {true},
}

@inproceedings{DBLP:conf/aist/NikishinaBK18,
  author       = {Irina Nikishina and
                  Amir Bakarov and
                  Andrey Kutuzov},
  title        = {RusNLP: Semantic Search Engine for Russian {NLP} Conference Papers},
  booktitle    = {{AIST}},
  series       = {Lecture Notes in Computer Science},
  volume       = {11179},
  pages        = {111--120},
  publisher    = {Springer},
  year         = {2018},
  bibtex_show= {true},
}

@inproceedings{Sysoev2018SmartCG,
  title={Smart Context Generation for Disambiguation to Wikipedia},
  author={Andrey Sysoev and Irina Nikishina},
  booktitle={Artificial Intelligence and Natural Language},
  year={2018},
  url={https://api.semanticscholar.org/CorpusID:69842254},
  bibtex_show= {true},
}

@article{bakarov2018russian,
  title={Russian computational linguistics: topical structure in 2007--2017 conference papers},
  author={Bakarov, Amir and Kutuzov, Andrey and Nikishina, Irina},
  journal={Proceedings of Dialogue-2018, online papers. ABBYY},
  year={2018},
  bibtex_show= {true}
}
